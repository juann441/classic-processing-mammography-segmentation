{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuv_3jFe3mqQ"
      },
      "source": [
        "# Strategy for Automatic Detection and Segmentation of Microcalcifications in Mammograms Using Image Processing and Lightweight Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfSCL4mQ1L1t",
        "outputId": "f5dbfddb-55f9-488f-e348-2c492a06d896"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjqn8qZR1ZEA",
        "outputId": "51044be7-96ab-402d-a4f6-2697cb5ca744"
      },
      "outputs": [],
      "source": [
        "pip install pydicom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9LTqwQ4qIEu"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kgZ_HiQgmmcI"
      },
      "outputs": [],
      "source": [
        "# Import python libraries\n",
        "import imageio as io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from skimage import io\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from skimage import data\n",
        "from skimage.filters import threshold_multiotsu\n",
        "import matplotlib\n",
        "from scipy.stats import linregress\n",
        "import math\n",
        "import random\n",
        "from skimage import io, color, filters, data, exposure\n",
        "from typing_extensions import assert_type\n",
        "import copy\n",
        "from pydicom import dcmread\n",
        "from scipy.stats import linregress\n",
        "import math\n",
        "import random\n",
        "from skimage import io, color, filters, data, exposure\n",
        "import time\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sqrt\n",
        "from skimage.feature import blob_dog, blob_log, blob_doh\n",
        "from skimage.filters import threshold_otsu\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHhlF-wEqK91"
      },
      "source": [
        "## FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBB53bUip7gE"
      },
      "outputs": [],
      "source": [
        "# Start time\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "# Open the image in pgm format\n",
        "def openImage(rute):\n",
        "  image= io.imread(rute)\n",
        "  return image\n",
        "\n",
        "# Image Size and Pixel Value Range\n",
        "def sizeImage(image):\n",
        "    \"\"\"Prints the dimensions and the minimum and maximum pixel values of the image.\"\"\"\n",
        "    print(f'Image dimensions: {image.shape}')\n",
        "    print(f'Minimum pixel value: {image.min()}')\n",
        "    print(f'Maximum pixel value: {image.max()}')\n",
        "\n",
        "\n",
        "# I normalize the cropped image and with Logarithmic tranf. I scale it from 0 to 1\n",
        "def normalize_image(img):\n",
        "    img_norm = (img - img.min()) / (img.max() - img.min())\n",
        "    return img_norm\n",
        "\n",
        "\n",
        "def plotImageTittle2(image, title, cmap = 'gray', size=100):\n",
        "    fig, ax = plt.subplots(dpi=size)\n",
        "    ax.imshow(image,cmap=cmap)\n",
        "    plt.title(str(title))\n",
        "    plt.show\n",
        "\n",
        "\n",
        "# Plot an image with  title\n",
        "def plotImageTittle(image, title, size=100):\n",
        "    fig, ax = plt.subplots(dpi=size)\n",
        "    ax.imshow(image,cmap='gray')\n",
        "    plt.title(str(title))\n",
        "    plt.show\n",
        "\n",
        "# Plot two horizontal images with title\n",
        "def plotImageTwoTittle(image1, image2, title1, title2, size=100):\n",
        "    fig, ax = plt.subplots(1, 2, dpi=size)\n",
        "    # First sub-graph\n",
        "    ax[0].imshow(image1, cmap='gray')\n",
        "    ax[0].set_axis_off()\n",
        "    ax[0].set_title(str(title1))\n",
        "    # Second sub-graph\n",
        "    ax[1].imshow(image2, cmap='gray')\n",
        "    ax[1].set_axis_off()\n",
        "    ax[1].set_title(str(title2))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "#  Plot three horizontal images with title\n",
        "def plotImageThreeTittle(image1, image2, image3, title1, title2, title3, size=400):\n",
        "    fig, ax = plt.subplots(1,3, dpi=size)\n",
        "    ax[0].imshow(image1, cmap='gray')\n",
        "    ax[0].set_axis_off()\n",
        "    ax[0].set_title(str(title1), fontsize=5)\n",
        "\n",
        "    ax[1].imshow(image2, cmap='gray')\n",
        "    ax[1].set_axis_off()\n",
        "    ax[1].set_title(str(title2), fontsize=5)\n",
        "\n",
        "    ax[2].imshow(image3, cmap='gray')\n",
        "    ax[2].set_axis_off()\n",
        "    ax[2].set_title(str(title3), fontsize=5)\n",
        "    plt.show()\n",
        "\n",
        "# Plot ten horizontal images with title\n",
        "\n",
        "\n",
        "# Define custom colormap\n",
        "custom_cmap = ListedColormap([\"blue\", \"green\", \"yellow\", \"red\", \"white\"])  # Ajusta colores si querés\n",
        "\n",
        "# Function to plot 10 images with titles\n",
        "def plotImageTenTittle2(img1, img2, img3, img4, img5, img6, img7, img8, img9, img10, t1, t2, t3, t4, t5, t6, t7, t8, t9, t10):\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(18, 6), dpi=200)\n",
        "    fig.subplots_adjust(hspace=0.1, wspace=0)\n",
        "\n",
        "    imgs = [img1, img2, img3, img4, img5, img6, img7, img8, img9, img10]\n",
        "    titles = [t1, t2, t3, t4, t5, t6, t7, t8, t9, t10]\n",
        "\n",
        "    for i, (img, title) in enumerate(zip(imgs, titles)):\n",
        "        ax = axes[i // 5, i % 5]\n",
        "\n",
        "        if i == 3:  # Cuarta imagen (índice 3) - Multi-Otsu\n",
        "            ax.imshow(img, cmap=custom_cmap)\n",
        "        elif i == len(imgs) - 1:\n",
        "            ax.imshow(img, cmap=\"seismic\")\n",
        "        else:\n",
        "            ax.imshow(img, cmap=\"gray\")\n",
        "\n",
        "        ax.axis('off')\n",
        "        ax.set_title(str(title), fontsize=10)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Plot a histogram - range=[0, 1]\n",
        "def histogram(img, n_bins, title=''):\n",
        "    h = img.ravel()\n",
        "    _, nbins = np.histogram(h, bins=n_bins, range=[0, 1])\n",
        "\n",
        "    plt.hist(h, bins=nbins, edgecolor='black')\n",
        "    plt.title(format(title))\n",
        "    #plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        " # Plot two histograms - range=[0, 1]\n",
        "def hyper_histogram(hyp1, hyp2, n_bins, title1='', title2=''):\n",
        "\n",
        "    h1 = hyp1[:,:].ravel()\n",
        "    h2 = hyp2[:,:].ravel()\n",
        "    _, nbins = np.histogram(h1, bins=n_bins, range=[0, 1])\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    axs[0].hist(h1, bins=nbins, edgecolor='black')\n",
        "    axs[0].set_title(format(title1))\n",
        "    plt.grid()\n",
        "    axs[1].hist(h2, bins=nbins, edgecolor='black')\n",
        "    axs[1].set_title(format(title2))\n",
        "    plt.grid()\n",
        "    plt.show\n",
        "\n",
        "# visualize image and histogram - range=[0, 1]\n",
        "def visualize_imag_histogram(image, n_bins=256, size=(12, 6), dpi=80, image_title='Grayscale Image', hist_title='Luminance Histogram'):\n",
        "    # Create a figure with two subplots: one for the image and one for the histogram\n",
        "    fig, axs = plt.subplots(1, 2, figsize=size, dpi=dpi)\n",
        "\n",
        "    # Display the grayscale image\n",
        "    axs[0].imshow(image, cmap='gray')\n",
        "    axs[0].set_title(image_title)\n",
        "    axs[0].axis('off')  # Hide the axes of the image\n",
        "\n",
        "    # Calculate and plot the histogram in the second subplot\n",
        "    axs[1].hist(image.ravel(), bins=n_bins, range=[0, 1], edgecolor='black')\n",
        "    axs[1].set_title(hist_title)\n",
        "    axs[1].set_xlabel('Luminance')\n",
        "    axs[1].set_ylabel('Frequency')\n",
        "    axs[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Crop images- DATASET: Mias\n",
        "def area_crop(image,x,y,r):\n",
        "    print('Coordinates for crop:',x ,\",\",y,\",\",r)\n",
        "    img_copy = np.copy(image)\n",
        "    y = image.shape[0] - y\n",
        "    img_recorte = img_copy[y-r:y+r, x-r:x+r]\n",
        "    return img_recorte\n",
        "\n",
        "\n",
        "# In this function the origin of coordinates is in the lower left corner\n",
        "# DATASET: Mias\n",
        "\n",
        "def draw_area(img,x, y, r):\n",
        "    #Image origin at (x=0, y=maximo_y)\n",
        "    print('Coordinates:',x ,\",\",y,\",\",r)\n",
        "    y = img.shape[0] - y\n",
        "    img_copy = np.copy(img)\n",
        "    cv2.line(img_copy,(x-r,y-r),(x+r,y-r),(255,0,0),4)\n",
        "    cv2.line(img_copy,(x-r,y+r),(x+r,y+r),(255,0,0),4)\n",
        "    cv2.line(img_copy,(x-r,y-r),(x-r,y+r),(255,0,0),4)\n",
        "    cv2.line(img_copy,(x+r,y-r),(x+r,y+r),(255,0,0),4)\n",
        "    plt.imshow(img_copy, cmap='gray')\n",
        "    #return img_copy\n",
        "\n",
        "\n",
        "\n",
        "# Draw a rectangle with four coordinates - dcm format\n",
        "def affected_area_dcm(img5, x1, y1, x2, y2, x3, y3, x4, y4):\n",
        "    img5_copy = np.copy(img5)\n",
        "\n",
        "    # Color in RGB format (255, 87, 51) corresponding to #FF5733\n",
        "    color = (255, 87, 51)\n",
        "\n",
        "    # Draw the rectangle lines in the specified color\n",
        "    cv2.line(img5_copy, (x1, y1), (x2, y2), color, 5)\n",
        "    cv2.line(img5_copy, (x2, y2), (x3, y3), color, 5)\n",
        "    cv2.line(img5_copy, (x3, y3), (x4, y4), color, 5)\n",
        "    cv2.line(img5_copy, (x4, y4), (x1, y1), color, 5)\n",
        "\n",
        "    return img5_copy\n",
        "\n",
        "\n",
        "# Function to CROP A mammographic - dcm format\n",
        "def image_crop_dcm(image, y1, y4, x1, x2):\n",
        "    image_crop = image[y1:y4, x1:x2]\n",
        "    return image_crop\n",
        "\n",
        "\n",
        "# from RGB to YIQ\n",
        "def rgb_to_y(matrix_rgb):\n",
        "    matrix_rgb = np.array(matrix_rgb)\n",
        "    coefficients = np.array([0.299, 0.587, 0.114])\n",
        "    matrix_y = np.dot(matrix_rgb, coefficients)\n",
        "    return matrix_y\n",
        "\n",
        "\n",
        "# Define a function to compute the optimal exponent factor based on pixel intensity distribution\n",
        "def calculate_optimal_exponent(image, percentile=90, lower_bound=2, upper_bound=20, scaling_factor=0.97):\n",
        "    # Calculate the specified percentile of pixel intensities\n",
        "    intensity_percentile = np.percentile(image, percentile / 100.0 * np.max(image))\n",
        "\n",
        "    # Suggest an exponent based on the computed percentile\n",
        "    suggested_n = lower_bound + (upper_bound - lower_bound) * (1 - intensity_percentile)\n",
        "\n",
        "    # Apply the scaling factor to adjust the suggested exponent\n",
        "    suggested_n_new = suggested_n * scaling_factor\n",
        "    print(f\"Original suggested exponent: {suggested_n}\")\n",
        "    print(f\"Using only {scaling_factor * 100}% of the suggested exponent. The new suggested exponent is: {suggested_n_new}\")\n",
        "\n",
        "    # Ensure the new exponent is within the specified range\n",
        "    return max(lower_bound, min(upper_bound, suggested_n_new))\n",
        "\n",
        "\n",
        "# Function to apply Multi-Otsu and decompress the thresholds\n",
        "def multi_Otsu(img_power, dpi=100):\n",
        "    plt.rcParams['font.size'] = 9\n",
        "    image = img_power\n",
        "    thresholds = threshold_multiotsu(image)\n",
        "    otsu_threshold1, otsu_threshold2 = thresholds\n",
        "    print(\"The Multi-Otsu threshold is:\", otsu_threshold1)\n",
        "    print(\"The Multi-Otsu threshold is:\", otsu_threshold2)\n",
        "    regions = np.digitize(image, bins=thresholds)\n",
        "\n",
        "    # Create subplots with the specified dpi\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 3.5), dpi=dpi)\n",
        "    ax[0].imshow(image, cmap='gray', clim=(0, 1))\n",
        "    ax[0].set_title('Power Image')\n",
        "    ax[0].axis('off')\n",
        "    ax[1].hist(image.ravel(), bins=30)\n",
        "    ax[1].set_title('Histogram')\n",
        "    for thresh in thresholds:\n",
        "        ax[1].axvline(thresh, color='r')\n",
        "    ax[2].imshow(regions, cmap='jet')\n",
        "    ax[2].set_title('Multi-Otsu (three types)')\n",
        "    ax[2].axis('off')\n",
        "    plt.subplots_adjust()\n",
        "    plt.show()\n",
        "\n",
        "    return regions, otsu_threshold1, otsu_threshold2\n",
        "\n",
        "# === BI-RADS 4 Classification Function ===\n",
        "def classify_suspicion_level(density):\n",
        "    \"\"\"\n",
        "    Classifies the suspicion level of a lesion based on its estimated malignancy risk percentage.\n",
        "    \"\"\"\n",
        "    if density > 2 and density <= 10:\n",
        "        return (\n",
        "            \"Category 4A: Low but sufficient suspicion (>2% to 10%).\\n\"\n",
        "        )\n",
        "    elif density > 10 and density <= 50:\n",
        "        return (\n",
        "            \"Category 4B: Moderate suspicion (>10% to 50%).\\n\"\n",
        "        )\n",
        "    elif density > 50 and density < 95:\n",
        "        return (\n",
        "            \"Category 4C: High suspicion (>50% to <95%).\\n\"\n",
        "        )\n",
        "    else:\n",
        "        return (\n",
        "            \"Outside BI-RADS 4A–4C range.\\n\"\n",
        "            \"- Either benign (<2%) or extremely suspicious (>95%).\\n\"\n",
        "            \"- Further assessment or different category may apply.\\n\"\n",
        "        )\n",
        "\n",
        "# After using the conventional Multi-Otsu, 4 classes are obtained in the mammogram according to their luminance\n",
        "\n",
        "\n",
        "def multi_Otsu_4zonesv2(img_power, dpi=100):\n",
        "    \"\"\"\n",
        "    This function performs a multi-level Otsu segmentation to divide a breast image\n",
        "    into three zones based on intensity thresholds and calculates key metrics for\n",
        "    breast density analysis and potential microcalcification detection.\n",
        "\n",
        "    Parameters:\n",
        "        img_power (ndarray): Input image normalized to [0, 1].\n",
        "        dpi (int): Resolution for the output visualization plots.\n",
        "\n",
        "    Returns:\n",
        "        regions (ndarray): Segmented image regions.\n",
        "        otsu_threshold1 (float): First Otsu threshold.\n",
        "        otsu_threshold2 (float): Second Otsu threshold.\n",
        "        interval_min (float): Lower bound of intensity interval for microcalcifications.\n",
        "        interval_max (float): Upper bound (fixed at 1.0).\n",
        "    \"\"\"\n",
        "    plt.rcParams['font.size'] = 9\n",
        "\n",
        "    # === Apply Multi-Otsu Thresholding ===\n",
        "    image = img_power\n",
        "    thresholds = threshold_multiotsu(image)\n",
        "    otsu_threshold1, otsu_threshold2 = thresholds\n",
        "    print(\"Multi-Otsu Threshold 1:\", otsu_threshold1)\n",
        "    print(\"Multi-Otsu Threshold 2:\", otsu_threshold2)\n",
        "\n",
        "    max_pixel_value = np.max(image)\n",
        "    print(\"Maximum pixel value:\", max_pixel_value)\n",
        "\n",
        "    # === Segment the image into 3 zones based on thresholds ===\n",
        "    zone_1_pixels = image[image < otsu_threshold1]\n",
        "    zone_2_pixels = image[(image >= otsu_threshold1) & (image < otsu_threshold2)]\n",
        "    zone_3_pixels = image[image >= otsu_threshold2]\n",
        "\n",
        "    # === Calculate area (number of pixels) in each zone ===\n",
        "    area_zone_1 = len(zone_1_pixels)\n",
        "    area_zone_2 = len(zone_2_pixels)\n",
        "    area_zone_3 = len(zone_3_pixels)\n",
        "    area_total = area_zone_1 + area_zone_2 + area_zone_3\n",
        "\n",
        "    # === Metric 2.1: Dense Breast Proportion (PDM-Z3) ===\n",
        "    if (area_zone_2 + area_zone_3) > 0:\n",
        "        pdm_z3 = (area_zone_3 / (area_zone_2 + area_zone_3)) * 100\n",
        "    else:\n",
        "        pdm_z3 = 0\n",
        "\n",
        "    print(f\"➤ Dense Breast Proportion (PDM-Z3): {pdm_z3:.2f}%\")\n",
        "    print(classify_suspicion_level(pdm_z3))\n",
        "\n",
        "    # === Metric 2.2: Proportion of Luminance in Dense Tissue (PLTD-Z3) ===\n",
        "    sum_luminance_zone_2 = np.sum(zone_2_pixels)\n",
        "    sum_luminance_zone_3 = np.sum(zone_3_pixels)\n",
        "    if (sum_luminance_zone_2 + sum_luminance_zone_3) > 0:\n",
        "        pltd_z3 = (sum_luminance_zone_3 / (sum_luminance_zone_2 + sum_luminance_zone_3)) * 100\n",
        "    else:\n",
        "        pltd_z3 = 0\n",
        "\n",
        "    print(f\"➤ Proportion of Luminance in Dense Tissue (PLTD-Z3) 💡: {pltd_z3:.2f}%\")\n",
        "\n",
        "    # === Metric 2.3: Luminance Averages in Dense Region (PL-Z3) ===\n",
        "    avg_zone_3 = np.mean(zone_3_pixels) if len(zone_3_pixels) > 0 else 0\n",
        "    alpha = 6\n",
        "    weights = np.exp(alpha * zone_3_pixels)\n",
        "    avg_weighted_zone_3 = (np.sum(zone_3_pixels * weights) / np.sum(weights)) if np.sum(weights) > 0 else 0\n",
        "\n",
        "    print(f\"✨ Classical luminance average in dense zone (PL-Z3 classical): {avg_zone_3:.2f}\")\n",
        "    print(f\"📈 Exponentially weighted luminance average in dense zone (PL-Z3 weighted): {avg_weighted_zone_3:.2f}\")\n",
        "\n",
        "    # === Metric 2.4: Probable Intensity Range for Microcalcifications (RIPM) ===\n",
        "    if avg_weighted_zone_3 * 1.15 > 1.0:\n",
        "        interval_min = 1.0\n",
        "    else:\n",
        "        interval_min = avg_weighted_zone_3 * 1.15\n",
        "    interval_max = 1.0\n",
        "\n",
        "    print(f\"➤🚨 Probable Intensity Range for Microcalcifications (RIPM): [{interval_min:.2f}, {interval_max:.2f}]\")\n",
        "\n",
        "    if interval_min > interval_max:\n",
        "        avg_intensity_interval = 0\n",
        "    else:\n",
        "        zone_3_in_interval = zone_3_pixels[(zone_3_pixels >= interval_min) & (zone_3_pixels <= interval_max)]\n",
        "        avg_intensity_interval = np.mean(zone_3_in_interval) if len(zone_3_in_interval) > 0 else 0\n",
        "\n",
        "    print(f\"💥 Average Intensity within RIPM Interval: {avg_intensity_interval:.2f}\")\n",
        "\n",
        "    # === Visualization of segmentation and histogram ===\n",
        "    regions = np.digitize(image, bins=thresholds)\n",
        "    mask_interval = (image >= interval_min) & (image <= interval_max)\n",
        "    segmentation_colors = plt.cm.jet(regions / regions.max())\n",
        "    segmentation_colors[mask_interval] = [1, 1, 1, 1]\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 3.5), dpi=dpi)\n",
        "    ax[0].imshow(image, cmap='gray')\n",
        "    ax[0].set_title('Power Image')\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    ax[1].hist(image.ravel(), bins=30)\n",
        "    ax[1].set_title('Intensity Histogram')\n",
        "    for idx, thresh in enumerate(thresholds):\n",
        "        ax[1].axvline(thresh, color='r', linestyle='--', label=f'Threshold {idx+1}: {thresh:.2f}')\n",
        "    ax[1].axvline(interval_min, color='g', linestyle='--', label=f'Interval Min: {interval_min:.2f}')\n",
        "    ax[1].axvline(interval_max, color='g', linestyle='--', label=f'Interval Max: {interval_max:.2f}')\n",
        "    ax[1].legend(loc='upper right')\n",
        "\n",
        "    ax[2].imshow(segmentation_colors)\n",
        "    ax[2].set_title('Segmentation with MC Highlighted in White')\n",
        "    ax[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # === Summary Table (Metrics 2.1 to 2.4) ===\n",
        "    metrics = {\n",
        "        \"Metric\": [\n",
        "            \"Dense Breast Proportion (PDM-Z3) (%)\",\n",
        "            \"Proportion of Luminance in Dense Tissue (PLTD-Z3) (%)\",\n",
        "            \"Classical Luminance Average in Dense Zone (PL-Z3 classical)\",\n",
        "            \"Exponentially Weighted Luminance Average in Dense Zone (PL-Z3 weighted)\",\n",
        "            \"Probable Intensity Range for Microcalcifications (RIPM)\",\n",
        "            \"Average Intensity within RIPM Interval\"\n",
        "        ],\n",
        "        \"Value\": [\n",
        "            f\"{pdm_z3:.2f}\",\n",
        "            f\"{pltd_z3:.2f}\",\n",
        "            f\"{avg_zone_3:.2f}\",\n",
        "            f\"{avg_weighted_zone_3:.2f}\",\n",
        "            f\"[{interval_min:.2f}, {interval_max:.2f}]\",\n",
        "            f\"{avg_intensity_interval:.2f}\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    df_metrics = pd.DataFrame(metrics)\n",
        "    print(\"\\n**Summary of Metrics:**\")\n",
        "    print(df_metrics)\n",
        "\n",
        "    multiotsu_results = {\n",
        "        'PDM_Z3': round(pdm_z3, 3),\n",
        "        'PLTD_Z3': round(pltd_z3, 3),\n",
        "        'PL_Z3_classical': round(avg_zone_3, 3),\n",
        "        'PL_Z3_weighted': round(avg_weighted_zone_3, 3),\n",
        "        'RIPM_min': round(interval_min, 3),\n",
        "        'RIPM_max': round(interval_max, 3),\n",
        "        'RIPM_avg': round(avg_intensity_interval, 3)\n",
        "    }\n",
        "\n",
        "    return segmentation_colors, regions, otsu_threshold1, otsu_threshold2, interval_min, interval_max, multiotsu_results\n",
        "\n",
        "\n",
        "\n",
        "# Function to create a bar chart and a table for pixel count and percentage\n",
        "def plot_and_table(image, regions, otsu_threshold1, otsu_threshold2, dpi=100):\n",
        "    # Define the masks for each class\n",
        "    mask_class1 = (regions == 0)\n",
        "    mask_class2 = (regions == 1)\n",
        "    mask_class3 = (regions == 2)\n",
        "\n",
        "    # Calculate the number of pixels in each class\n",
        "    count_class1 = np.count_nonzero(mask_class1)\n",
        "    count_class2 = np.count_nonzero(mask_class2)\n",
        "    count_class3 = np.count_nonzero(mask_class3)\n",
        "\n",
        "    # Total number of pixels\n",
        "    total_pixels = regions.size\n",
        "\n",
        "    # Calculate the percentage of pixels in each class\n",
        "    percent_class1 = (count_class1 / total_pixels) * 100\n",
        "    percent_class2 = (count_class2 / total_pixels) * 100\n",
        "    percent_class3 = (count_class3 / total_pixels) * 100\n",
        "\n",
        "    # Calculate the mean and standard deviation for each class using the original image\n",
        "    mean_class1 = np.mean(image[mask_class1])\n",
        "    std_class1 = np.std(image[mask_class1])\n",
        "    mean_class2 = np.mean(image[mask_class2])\n",
        "    std_class2 = np.std(image[mask_class2])\n",
        "    mean_class3 = np.mean(image[mask_class3])\n",
        "    std_class3 = np.std(image[mask_class3])\n",
        "\n",
        "    # Define the intervals for each class\n",
        "    intervals = [\n",
        "        f\"(0, {otsu_threshold1:.6f})\",\n",
        "        f\"({otsu_threshold1:.6f}, {otsu_threshold2:.6f})\",\n",
        "        f\"({otsu_threshold2:.6f}, 1)\"\n",
        "    ]\n",
        "\n",
        "    # Create a DataFrame for the table\n",
        "    data = {\n",
        "        'Class': ['Class 1 (Blue)', 'Class 2 (Green)', 'Class 3 (Red)'],\n",
        "        'Value Range': intervals,\n",
        "        'Pixel Count': [count_class1, count_class2, count_class3],\n",
        "        'Pixel Percentage (%)': [round(percent_class1, 6), round(percent_class2, 6), round(percent_class3, 6)],\n",
        "        'Mean Value': [f\"{mean_class1:.6f}\", f\"{mean_class2:.6f}\", f\"{mean_class3:.6f}\"],\n",
        "        'Standard Deviation': [f\"{std_class1:.6f}\", f\"{std_class2:.6f}\", f\"{std_class3:.6f}\"]\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Adjust pandas display settings to show 6 decimal places\n",
        "    pd.set_option('display.float_format', '{:.6f}'.format)\n",
        "\n",
        "    # Print the table\n",
        "    print(\"\\nResults Table:\")\n",
        "    print(df)\n",
        "\n",
        "    # Create a bar chart for the pixel count per class\n",
        "    fig, ax = plt.subplots(dpi=dpi)\n",
        "    ax.bar(df['Class'], df['Pixel Count'], color=['blue', 'green', 'red'])\n",
        "    ax.set_title('Pixel Count per Class')\n",
        "    ax.set_xlabel('Class')\n",
        "    ax.set_ylabel('Pixel Count')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "# opening filter\n",
        "def opening_filter(image):\n",
        "    # Realiza la operación de apertura morfológica\n",
        "    kernel = np.ones((2,2), np.uint8)  # Definir un kernel de 3x3\n",
        "    opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
        "    return opening  # Asegúrate de retornar el resultado\n",
        "\n",
        "\n",
        "# Anscombe transformation\n",
        "def anscombe(img):\n",
        "    img_anscombe= 2.0*np.sqrt(img + 3.0/8.0)\n",
        "    sizeImage(img_anscombe)\n",
        "    return(img_anscombe)\n",
        "\n",
        "\n",
        "# Intensity using the cosine function\n",
        "def cosine_function(img):\n",
        "    img_cosine= 1-np.cos((np.pi/2)*(img/255.0))\n",
        "    sizeImage(img_cosine)\n",
        "    return(img_cosine)\n",
        "\n",
        "\n",
        "# DoG filter function (difference of gaussians)\n",
        "def DoG_filter(img, k1, k2):\n",
        "    # apply a gaussian blur with a 3x3 kernel to create the lower-frequency component\n",
        "    dog_low = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "\n",
        "    # apply a gaussian blur with a 5x5 kernel to create the higher-frequency component\n",
        "    dog_high = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "\n",
        "    # calculate the difference of gaussians (DoG) by combining the two blurred images with specified weights\n",
        "    dog = k1 * dog_low - k2 * dog_high\n",
        "\n",
        "    # return the resulting dog image\n",
        "    return dog\n",
        "\n",
        "\n",
        "\n",
        "# Change colors of Otsu thresholding (black to white)\n",
        "def apply_otsu_and_plot(image, title, size=100):\n",
        "    # Copiar la imagen normalizada\n",
        "    image_copy = copy.copy(image)\n",
        "\n",
        "    # Calcular el umbral de Otsu\n",
        "    otsu_threshold = threshold_otsu(image)\n",
        "\n",
        "    # Aplicar el umbral de Otsu\n",
        "    image_copy[image <= otsu_threshold] = 1\n",
        "    image_copy[image > otsu_threshold] = 0\n",
        "\n",
        "    # Retornar la imagen procesada\n",
        "    return image_copy\n",
        "\n",
        "\n",
        "\n",
        "# Overlays an RGB color on an image based on a segmentation mask\n",
        "def painting_segmented_end(img, mask, color_rgb=[57, 255, 0]):\n",
        "    \"\"\"\n",
        "    Overlays an RGB color on an image based on a segmentation mask.\n",
        "\n",
        "    Parameters:\n",
        "    img (numpy array): Input grayscale image to be processed.\n",
        "    mask (numpy array): Binary mask where 0 indicates the regions to be colored.\n",
        "    color_rgb (list, optional): RGB color to apply to the segmented regions.\n",
        "                                Default is [57, 255, 0] (light green).\n",
        "\n",
        "    Returns:\n",
        "    numpy array: RGB image with the segmented regions painted in the specified color.\n",
        "    \"\"\"\n",
        "\n",
        "    # Normalize the input image to the range [0, 1]\n",
        "    img = normalize_image(img)\n",
        "\n",
        "    # Convert the grayscale image to an RGB format by stacking it across three channels\n",
        "    img_rgb = np.stack((img, img, img), axis=-1)\n",
        "\n",
        "    # Scale the image to the range [0, 255] and convert it to an 8-bit unsigned integer\n",
        "    img_rgb = img_rgb * 255.0\n",
        "    img_rgb = img_rgb.astype(np.uint8)\n",
        "\n",
        "    # Apply the specified RGB color to the regions where the mask is 0\n",
        "    img_rgb[mask == 0, 0] = color_rgb[0]  # Red channel\n",
        "    img_rgb[mask == 0, 1] = color_rgb[1]  # Green channel\n",
        "    img_rgb[mask == 0, 2] = color_rgb[2]  # Blue channel\n",
        "\n",
        "    return img_rgb\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# F - blobs_with_visualization\n",
        "\n",
        "# F - blobs_with_visualization\n",
        "\n",
        "\n",
        "# F - blobs_with_visualization\n",
        "\n",
        "def analyze_blobs_with_visualization(imag_power, pixel_to_mm=0.2, max_sigma=10):\n",
        "    \"\"\"\n",
        "    Detects and classifies blobs in the given image using LoG, DoG, and DoH methods.\n",
        "    Displays the detections and prints blob counts and average diameters per size category.\n",
        "    Also shows bar plots with summary statistics.\n",
        "    \"\"\"\n",
        "    from math import sqrt\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    from skimage.feature import blob_log, blob_dog, blob_doh\n",
        "\n",
        "    # ---------------------------------------\n",
        "    # BLOB DETECTION\n",
        "    # ---------------------------------------\n",
        "    blobs_log = blob_log(imag_power, min_sigma=0.9, max_sigma=max_sigma, threshold=0.09)\n",
        "    blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2)\n",
        "\n",
        "    blobs_dog = blob_dog(imag_power, min_sigma=0.9, max_sigma=max_sigma, threshold=0.09)\n",
        "    blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n",
        "\n",
        "    blobs_doh = blob_doh(imag_power, min_sigma=0.9, max_sigma=max_sigma, threshold=0.09)\n",
        "\n",
        "    blobs_list = [blobs_log, blobs_dog, blobs_doh]\n",
        "    titles = ['LoG', 'DoG', 'DoH']\n",
        "\n",
        "    categories = {\n",
        "        \"d < 0.1 mm\": lambda d: d < 0.1,\n",
        "        \"0.1 ≤ d ≤ 1.5 mm\": lambda d: 0.1 <= d <= 1.5,\n",
        "        \"d > 1.5 mm\": lambda d: d > 1.5\n",
        "    }\n",
        "\n",
        "    blob_counts = {det: {cat: 0 for cat in categories} | {'total': 0} for det in titles}\n",
        "    blob_diameters = {det: {cat: [] for cat in categories} for det in titles}\n",
        "\n",
        "    # ---------------------------------------\n",
        "    # VISUALIZATION\n",
        "    # ---------------------------------------\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    for idx, (blobs, title) in enumerate(zip(blobs_list, titles)):\n",
        "        axes[idx].set_title(title)\n",
        "        axes[idx].imshow(imag_power, cmap=\"gray\")\n",
        "        img_height, img_width = imag_power.shape\n",
        "\n",
        "        for blob in blobs:\n",
        "            y, x, r = blob\n",
        "            radius_mm = r * pixel_to_mm\n",
        "            diameter_mm = 2 * radius_mm\n",
        "\n",
        "            for label, condition in categories.items():\n",
        "                if condition(diameter_mm):\n",
        "                    if label == \"d < 0.1 mm\":\n",
        "                        color = 'blue'\n",
        "                    elif label == \"0.1 ≤ d ≤ 1.5 mm\":\n",
        "                        color = 'red'\n",
        "                    else:\n",
        "                        color = 'yellow'\n",
        "\n",
        "                    blob_counts[title][label] += 1\n",
        "                    blob_counts[title]['total'] += 1\n",
        "                    blob_diameters[title][label].append(diameter_mm)\n",
        "                    break\n",
        "\n",
        "            # Draw circle\n",
        "            circle = plt.Circle((x, y), r, color=color, linewidth=1.5, fill=False)\n",
        "            axes[idx].add_patch(circle)\n",
        "\n",
        "            # Position label\n",
        "            offset = 5\n",
        "            text_y = y - r - offset\n",
        "            if text_y < 10:\n",
        "                text_y = y + r + offset\n",
        "            if text_y > img_height - 10:\n",
        "                text_y = img_height - 10\n",
        "\n",
        "            text_x = max(10, min(x, img_width - 10))\n",
        "\n",
        "            if (10 <= text_x <= img_width - 10) and (10 <= text_y <= img_height - 10):\n",
        "                axes[idx].text(\n",
        "                    text_x, text_y, f\"{diameter_mm:.2f} mm\",\n",
        "                    color=color, fontsize=6, fontweight='bold', ha=\"center\"\n",
        "                )\n",
        "\n",
        "        axes[idx].set_xlim(0, img_width)\n",
        "        axes[idx].set_ylim(img_height, 0)\n",
        "        axes[idx].set_axis_off()\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
        "    plt.show()\n",
        "\n",
        "    results = {}\n",
        "    results['Detector'] = []\n",
        "    results['Total_blobs'] = []\n",
        "    results['Blobs_candidates'] = []\n",
        "    results['percent_medium_candidates'] = []\n",
        "    results['Average_diameter_candidates'] = []\n",
        "\n",
        "    # ---------------------------------------\n",
        "    # OUTPUT SUMMARY\n",
        "    # ---------------------------------------\n",
        "    print(\"\\n📊 Blob count and average diameter by detector and size range:\")\n",
        "    for detector in titles:\n",
        "        total = blob_counts[detector]['total']\n",
        "        medium = blob_counts[detector][\"0.1 ≤ d ≤ 1.5 mm\"]\n",
        "        percent_medium = (medium / total * 100) if total > 0 else 0\n",
        "        blob_counts[detector]['medium_percent'] = percent_medium  # Added to dictionary\n",
        "        results['Detector'].append(detector)\n",
        "        results['Total_blobs'].append(total)\n",
        "\n",
        "        print(f\"\\n🧠 {detector}:\")\n",
        "        for cat in categories:\n",
        "            count = blob_counts[detector][cat]\n",
        "            diameters = blob_diameters[detector][cat]\n",
        "            average = np.mean(diameters) if diameters else 0\n",
        "            if cat == \"0.1 ≤ d ≤ 1.5 mm\":\n",
        "                results['Blobs_candidates'].append(count)\n",
        "                results['percent_medium_candidates'].append(round(percent_medium, 3))\n",
        "                results['Average_diameter_candidates'].append(round(average, 3))\n",
        "\n",
        "            print(f\"  {cat}: {count} blobs | average diameter = {average:.3f} mm\")\n",
        "        print(f\"  TOTAL: {total} blobs\")\n",
        "        print(f\"  ✅ 0.1–1.5 mm blobs = {medium} ({percent_medium:.1f}%)\")\n",
        "\n",
        "    # ---------------------------------------\n",
        "    # BAR CHART SUMMARY\n",
        "    # ---------------------------------------\n",
        "    total_counts = [blob_counts[det]['total'] for det in titles]\n",
        "    avg_radii = []\n",
        "    count_medium = []  # Count of blobs with 0.1 ≤ d ≤ 1.5 mm\n",
        "\n",
        "    for det in titles:\n",
        "        all_diameters = []\n",
        "        for diam_list in blob_diameters[det].values():\n",
        "            all_diameters.extend(diam_list)\n",
        "        avg_radius = np.mean(all_diameters) / 2 if all_diameters else 0\n",
        "        avg_radii.append(avg_radius)\n",
        "\n",
        "        count_medium.append(blob_counts[det][\"0.1 ≤ d ≤ 1.5 mm\"])\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "    bar_width = 0.25\n",
        "    index = np.arange(len(titles))\n",
        "\n",
        "    # First axis: Total blobs and medium blobs\n",
        "    bars1 = ax1.bar(index, total_counts, bar_width, label='Total Blobs', color='skyblue')\n",
        "    bars2 = ax1.bar(index + bar_width, count_medium, bar_width, label='0.1–1.5 mm Blobs', color='lightgreen')\n",
        "    ax1.set_ylabel('Blob Count')\n",
        "    ax1.set_xticks(index + bar_width / 2)\n",
        "    ax1.set_xticklabels(titles)\n",
        "    ax1.set_title('Blob Detection Summary')\n",
        "\n",
        "    # Second axis: Avg radius\n",
        "    ax2 = ax1.twinx()\n",
        "    bars3 = ax2.bar(index + 2 * bar_width, avg_radii, bar_width, label='Avg. Radius (mm)', color='orange')\n",
        "    ax2.set_ylabel('Avg. Radius (mm)')\n",
        "\n",
        "    # Legends\n",
        "    ax1.legend(loc='upper left')\n",
        "    ax2.legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return blob_counts, blob_diameters, results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrZ-TkKKpqy0"
      },
      "source": [
        "# EXECUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaP_maGIGWRB"
      },
      "outputs": [],
      "source": [
        "def procces(path, img_files, data_file):\n",
        "\n",
        "\n",
        "    multiotsu_general_results = {}\n",
        "    multiotsu_general_results['Image_name'] = []\n",
        "    multiotsu_general_results['Tissue'] = []\n",
        "    multiotsu_general_results['Abnormality'] = []\n",
        "    multiotsu_general_results['Severity'] = []\n",
        "    multiotsu_general_results['PDM_Z3'] = []\n",
        "    multiotsu_general_results['PLTD_Z3'] = []\n",
        "    multiotsu_general_results['PL_Z3_classical'] = []\n",
        "    multiotsu_general_results['PL_Z3_weighted'] = []\n",
        "    multiotsu_general_results['RIPM_min'] = []\n",
        "    multiotsu_general_results['RIPM_max'] = []\n",
        "    multiotsu_general_results['RIPM_avg'] = []\n",
        "\n",
        "    blobs_general_results = {}\n",
        "    blobs_general_results['Image_name'] = []\n",
        "    blobs_general_results['Tissue'] = []\n",
        "    blobs_general_results['Abnormality'] = []\n",
        "    blobs_general_results['Severity'] = []\n",
        "    blobs_general_results['Detector'] = []\n",
        "    blobs_general_results['Total_blobs'] = []\n",
        "    blobs_general_results['Blobs_candidates'] = []\n",
        "    blobs_general_results['percent_medium_candidates'] = []\n",
        "    blobs_general_results['Average_diameter_candidates'] = []\n",
        "\n",
        "    df_data = pd.read_csv(path + data_file, delimiter=';')\n",
        "    print('keys', df_data.keys())\n",
        "    for i, f in enumerate(img_files):\n",
        "      if i < 370: ###### Control de cantidad de imagenes a ejecutar\n",
        "        print(f'Processing image: {f}')\n",
        "        img_route = path + f\n",
        "        img_name = img_route.split('/')[-1]\n",
        "        img_name = img_name.split('.')[0]\n",
        "        # Extraer coordenadas del archivo de datos para la imagen\n",
        "        df_filter = df_data[df_data.Name == img_name]\n",
        "        if df_filter.empty:\n",
        "          print(f\"No se encontraron coordenadas para la imagen: {img_name}\")\n",
        "        else:\n",
        "          #print(f'Processing image: {f}')\n",
        "          x = df_filter.Coordinate_x.values[0]\n",
        "          y = df_filter.Coordinate_y.values[0]\n",
        "          r = df_filter.Radius.values[0]\n",
        "          # extract data\n",
        "          tissue = df_filter.Tissue.values[0]\n",
        "          abnormality = df_filter.Abnormality.values[0]\n",
        "          severity = df_filter.Severity.values[0]\n",
        "          # Abrir y graficar imagen\n",
        "          initial_img = openImage(img_route)\n",
        "          plotImageTittle(initial_img, \"Mammography\", size=100)\n",
        "          sizeImage(initial_img)\n",
        "          #Dibujar zona de interes y hacer recorte de la zona\n",
        "          img_box = draw_area(initial_img, x, y, r)\n",
        "          imag_crop= area_crop(initial_img, x, y, r)\n",
        "          #Normalizacion de la imagen\n",
        "          imag_crop_norm = normalize_image(imag_crop)\n",
        "          #Filtro de potencia\n",
        "          optimal_n = calculate_optimal_exponent(imag_crop_norm, percentile=90, lower_bound=2, upper_bound=20, scaling_factor=0.15)\n",
        "          imag_power = imag_crop_norm**optimal_n\n",
        "          #Multiotsu\n",
        "          imag_multiOtsu, otsu_threshold1, otsu_threshold2 = multi_Otsu(imag_power, dpi=100)\n",
        "          df = plot_and_table(imag_power, imag_multiOtsu, otsu_threshold1, otsu_threshold2, dpi=70)\n",
        "          #Multiotsu 4 zonas\n",
        "          img_fiveotsu, regions, _, _ , interva_max, interval_max, multiotsu_results = multi_Otsu_4zonesv2(imag_power)\n",
        "          imag_multiOtsu_copy1 = copy.copy(imag_power)\n",
        "          intervalo_min, intervalo_max =interva_max, interval_max  #0.72, 1  # Reemplaza con los valores reales de tu función multi_Otsu3\n",
        "          print(\" Probable intensity interval for microcalcifications from multi_Otsu_4zones:\",\"(\", interva_max ,\";\",interval_max,\")\")\n",
        "          # Apply thresholding based on the probable interval\n",
        "          imag_multiOtsu_copy1[imag_multiOtsu_copy1 < intervalo_min] = 0\n",
        "          imag_multiOtsu_copy1[imag_multiOtsu_copy1 >= intervalo_min] = 1\n",
        "          # Display the resulting image\n",
        "          imag_multiOtsu_norm = normalize_image(imag_multiOtsu_copy1)\n",
        "          # Opening Filter\n",
        "          imag_opening = opening_filter(imag_multiOtsu_copy1).astype(np.float32)  # Convert to float32 if necessary\n",
        "          imag_opening_norm = normalize_image(imag_opening)\n",
        "          #Convolution between the Otsu mask refined with the opening filter and the image corresponding to the mammogram crop\n",
        "          imag_crop_norm_copy = copy.copy(imag_crop_norm)\n",
        "          imag_crop_norm_copy[imag_opening_norm == 0] = 0\n",
        "          # Anscombe transformation\n",
        "          imag_anscombe = anscombe(imag_crop_norm_copy)\n",
        "          imag_anscombe_norm = normalize_image(imag_anscombe)\n",
        "          # Cosine function\n",
        "          imag_cosine= cosine_function(imag_anscombe_norm)\n",
        "          imag_cosine_norm = normalize_image(imag_cosine)\n",
        "          # DoG filter\n",
        "          img_dog = DoG_filter(imag_cosine_norm, k1=1.1, k2=0.9)\n",
        "          img_dog_norm = normalize_image(img_dog)\n",
        "          # Final image\n",
        "          final_image= img_dog_norm*imag_crop_norm_copy\n",
        "          final_image_norm = normalize_image(final_image)\n",
        "          #Change colors of Otsu thresholding (black to white)\n",
        "          imag_dog_norm_copy = apply_otsu_and_plot(img_dog_norm, \"end\", size=100)\n",
        "          # Segmented microcalcification\n",
        "          copy_crop= copy.copy(imag_crop_norm)\n",
        "          copy_crop_rgb = painting_segmented_end(img=copy_crop, mask=imag_dog_norm_copy, color_rgb=[255, 0, 128])\n",
        "          # All images\n",
        "          plotImageTenTittle2(initial_img, imag_crop_norm, imag_power, img_fiveotsu, imag_opening_norm,\n",
        "                              imag_anscombe_norm, imag_cosine_norm, img_dog_norm,  final_image_norm, copy_crop_rgb,\n",
        "                              'Mammography','Crop','Power','MultiOtsu','Opening','Anscombe',\n",
        "                              'Cosine','DoG','Seg microcalcification','Colormaps')\n",
        "          # Analyze blobs with visualization\n",
        "          counts, diameters, blobs_results = analyze_blobs_with_visualization(imag_power)\n",
        "\n",
        "          # Save data in dictionary\n",
        "          multiotsu_general_results['Image_name'].append(img_name)\n",
        "          multiotsu_general_results['Tissue'].append(tissue)\n",
        "          multiotsu_general_results['Abnormality'].append(abnormality)\n",
        "          multiotsu_general_results['Severity'].append(severity)\n",
        "          multiotsu_general_results['PDM_Z3'].append(multiotsu_results['PDM_Z3'])\n",
        "          multiotsu_general_results['PLTD_Z3'].append(multiotsu_results['PLTD_Z3'])\n",
        "          multiotsu_general_results['PL_Z3_classical'].append(multiotsu_results['PL_Z3_classical'])\n",
        "          multiotsu_general_results['PL_Z3_weighted'].append(multiotsu_results['PL_Z3_weighted'])\n",
        "          multiotsu_general_results['RIPM_min'].append(multiotsu_results['RIPM_min'])\n",
        "          multiotsu_general_results['RIPM_max'].append(multiotsu_results['RIPM_max'])\n",
        "          multiotsu_general_results['RIPM_avg'].append(multiotsu_results['RIPM_avg'])\n",
        "\n",
        "          for idx in range(len(blobs_results['Detector'])):\n",
        "            blobs_general_results['Image_name'].append(img_name)\n",
        "            blobs_general_results['Tissue'].append(tissue)\n",
        "            blobs_general_results['Abnormality'].append(abnormality)\n",
        "            blobs_general_results['Severity'].append(severity)\n",
        "            blobs_general_results['Detector'].append(blobs_results['Detector'][idx])\n",
        "            blobs_general_results['Total_blobs'].append(blobs_results['Total_blobs'][idx])\n",
        "            blobs_general_results['Blobs_candidates'].append(blobs_results['Blobs_candidates'][idx])\n",
        "            blobs_general_results['percent_medium_candidates'].append(blobs_results['percent_medium_candidates'][idx])\n",
        "            blobs_general_results['Average_diameter_candidates'].append(blobs_results['Average_diameter_candidates'][idx])\n",
        "\n",
        "    return multiotsu_general_results, blobs_general_results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaAKwk7R2rM6"
      },
      "outputs": [],
      "source": [
        "def main(path):\n",
        "    \"\"\" This method makes general validations and begins the\n",
        "    #\tthe process of the meshes found. \"\"\"\n",
        "\n",
        "    files = os.listdir(path)\n",
        "    img_files = [x for x in files if \".pgm\" in x]\n",
        "    img_files = sorted(img_files)\n",
        "    data_file = [x for x in files if \"Data_base_mias.csv\" in x][0]\n",
        "\n",
        "    # Checking existing files to process\n",
        "    if len(files) > 0:\n",
        "      print(\"Number of images found: {}\".format(len(files)))\n",
        "      multiotsu_general_results, blobs_general_results = procces(path, img_files, data_file)\n",
        "      df_multiotsu = pd.DataFrame(multiotsu_general_results)\n",
        "      df_blobs = pd.DataFrame(blobs_general_results)\n",
        "      # Save results\n",
        "      df_multiotsu.to_csv(path + 'Results_mias_multiotsu.csv', index=False, sep=';')\n",
        "      df_blobs.to_csv(path + 'Results_mias_blobs2.csv', index=False, sep=';')\n",
        "      #print(df_multiotsu.head(10))\n",
        "      #print(df_blobs.head(10))\n",
        "    else:\n",
        "      print( \"Data folder doesn't contain any '.pgm' files to process...\")\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mXqYUxIw7sUr",
        "outputId": "b0b0c0dc-8b26-4c04-8e5c-a34498aa41ea"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/projet_uns/mamografias_mias_2025/'\n",
        "main(path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
